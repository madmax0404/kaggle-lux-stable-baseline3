{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Modified_lux3_wrapper.modified_wrappers_20250228_01 import ModifiedLuxAIS3GymEnv\n",
    "import numpy as np\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.vec_env import SubprocVecEnv\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "# from torch.optim import AdamW\n",
    "import os\n",
    "# import copy\n",
    "# from GreedyLRScheduler import GreedyLR\n",
    "# from luxai_s3.wrappers import LuxAIS3GymEnv\n",
    "import gc\n",
    "gc.enable()\n",
    "# from stable_baselines3.common.buffers import DictRolloutBuffer\n",
    "# from tqdm.notebook import tqdm\n",
    "from stable_baselines3.common.torch_layers import BaseFeaturesExtractor\n",
    "from stable_baselines3.common.policies import MultiInputActorCriticPolicy\n",
    "from gymnasium import spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_float32_matmul_precision('high')\n",
    "torch._dynamo.config.capture_scalar_outputs = True\n",
    "torch._dynamo.config.cache_size_limit = 128\n",
    "# os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n",
    "np.set_printoptions(linewidth=200)\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True,max_split_size_mb:512\"\n",
    "torch.backends.cudnn.benchmark = True\n",
    "torch.cuda.set_per_process_memory_fraction(0.8)\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:2025-03-07 18:34:30,314:jax._src.xla_bridge:966: An NVIDIA GPU may be present on this machine, but a CUDA-enabled jaxlib is not installed. Falling back to cpu.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "common policies actorcriticpolicy _build_mlp_extractor\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 1e-6\n",
    "env = ModifiedLuxAIS3GymEnv(numpy_output=True)\n",
    "model = PPO(\"MultiInputPolicy\", env, verbose=1, learning_rate=learning_rate, ent_coef=0.015, vf_coef=0.75, clip_range_vf=0.15, clip_range=0.2, n_steps=505, batch_size=101, max_grad_norm=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_observation(obs: dict, obs_space: spaces.Dict) -> dict:\n",
    "    \"\"\"\n",
    "    Normalize continuous features in the observation dict using min-max scaling,\n",
    "    while leaving discrete or binary features unchanged.\n",
    "    \"\"\"\n",
    "    norm_obs = {}\n",
    "    for key, space in obs_space.spaces.items():\n",
    "        value = obs[key]\n",
    "        # For Box spaces with numeric types (and not MultiBinary)\n",
    "        if isinstance(space, spaces.Box) and np.issubdtype(space.dtype, np.number):\n",
    "            # If the range is [0,1] (or binary), assume it's already normalized\n",
    "            if (space.low == 0).all() and (space.high == 1).all():\n",
    "                norm_obs[key] = value\n",
    "            else:\n",
    "                # Convert to float and apply min-max normalization:\n",
    "                # norm = (value - low) / (high - low)\n",
    "                low = torch.tensor(space.low, device=value.device, dtype=torch.float32)\n",
    "                high = torch.tensor(space.high, device=value.device, dtype=torch.float32)\n",
    "                # print(value)\n",
    "                norm_obs[key] = (value.to(dtype=torch.float32) - low) / (high - low + 1e-8)\n",
    "        else:\n",
    "            # For discrete or MultiBinary spaces, just copy the values\n",
    "            norm_obs[key] = value\n",
    "    return norm_obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomFeatureExtractor(BaseFeaturesExtractor):\n",
    "    \"\"\"\n",
    "    Custom feature extractor that:\n",
    "    - Processes 24x24 grid features using CNN.\n",
    "    - Flattens and concatenates other features.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, observation_space: spaces.Dict, features_dim: int = 0):\n",
    "        super(CustomFeatureExtractor, self).__init__(observation_space, features_dim)\n",
    "\n",
    "        # Identify 24x24 grid features\n",
    "        self.grid_features = [\"map_explored_status\", \"map_features_energy\", \"map_features_tile_type\", \"sensor_mask\"]\n",
    "        self.features = []\n",
    "        for key in observation_space.keys():\n",
    "            self.features.append(key)\n",
    "\n",
    "        # **CNN for 24x24 Grid Features** (Expects input shape [batch, channels, 24, 24])\n",
    "        self.cnn_extractor = nn.Sequential(\n",
    "            nn.Conv2d(len(self.grid_features), 16, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.SiLU(),\n",
    "            nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.SiLU(),\n",
    "            nn.Flatten(),\n",
    "            nn.Dropout(0.1),\n",
    "        )\n",
    "\n",
    "        self.cnn_extractor = torch.compile(self.cnn_extractor)\n",
    "\n",
    "        # Compute CNN output dimension (using a dummy input)\n",
    "        dummy_input = torch.zeros((1, len(self.grid_features), 24, 24))\n",
    "        cnn_output_dim = self.cnn_extractor(dummy_input).shape[1]\n",
    "\n",
    "        # **Flatten layers for non-grid features**\n",
    "        self.extractors = nn.ModuleDict()\n",
    "        flatten_dim = 0\n",
    "\n",
    "        for key in observation_space.keys():\n",
    "            # print(key)\n",
    "            space_shape = observation_space.spaces[key].shape\n",
    "            self.extractors[key] = nn.Flatten()\n",
    "            flatten_dim += torch.prod(torch.tensor(space_shape)).item()\n",
    "\n",
    "        # Compute total feature dimension\n",
    "        self._features_dim = cnn_output_dim + flatten_dim\n",
    "\n",
    "    def forward(self, observations):\n",
    "        \"\"\"\n",
    "        Forward pass:\n",
    "        - Grid features go through CNN\n",
    "        - Other features are flattened\n",
    "        - Both are concatenated into a single tensor\n",
    "        \"\"\"\n",
    "        # observations = normalize_observation(observations, model.observation_space)\n",
    "\n",
    "        grid_stack = torch.stack([observations[key] for key in self.grid_features], dim=1).float()\n",
    "        grid_features = self.cnn_extractor(grid_stack)\n",
    "\n",
    "        # Flatten vector features\n",
    "        features = torch.cat([self.extractors[key](observations[key]) for key in self.features], dim=1)\n",
    "\n",
    "        combined_features = torch.cat([grid_features, features], dim=1)\n",
    "\n",
    "        return combined_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "common policies actorcriticpolicy _build_mlp_extractor\n"
     ]
    }
   ],
   "source": [
    "policy_kwargs = dict(\n",
    "    features_extractor_class=CustomFeatureExtractor,\n",
    "    features_extractor_kwargs=dict(features_dim=20897),\n",
    "    activation_fn=nn.SiLU,\n",
    "    # net_arch=dict(pi=[8192, 4096, 2048, 1024], vf=[8192, 4096, 2048, 1024, 512, 256, 128, 64]),\n",
    "    net_arch=dict(pi=[4096, 2048, 1024], vf=[4096, 2048, 1024, 512, 256, 128]),\n",
    "    # net_arch=dict(pi=[128, 64], vf=[128, 64]),\n",
    ")\n",
    "learning_rate = 2e-5\n",
    "env = ModifiedLuxAIS3GymEnv(numpy_output=True)\n",
    "model = PPO(\n",
    "    \"MultiInputPolicy\", env, policy_kwargs=policy_kwargs, verbose=0, learning_rate=learning_rate, ent_coef=0.015, vf_coef=0.75, clip_range_vf=0.3, clip_range=0.2, n_steps=505, batch_size=505,\n",
    "    max_grad_norm=0.5, n_epochs=10, save_dir=\"saved_policies/\", tensorboard_log=\"logs/\", gamma=0.99, target_kl=None, gae_lambda=0.9\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiInputActorCriticPolicy(\n",
       "  (features_extractor): CustomFeatureExtractor(\n",
       "    (cnn_extractor): OptimizedModule(\n",
       "      (_orig_mod): Sequential(\n",
       "        (0): Conv2d(4, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): SiLU()\n",
       "        (3): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): SiLU()\n",
       "        (6): Flatten(start_dim=1, end_dim=-1)\n",
       "        (7): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (extractors): ModuleDict(\n",
       "      (enemy_energies): Flatten(start_dim=1, end_dim=-1)\n",
       "      (enemy_positions): Flatten(start_dim=1, end_dim=-1)\n",
       "      (enemy_spawn_location): Flatten(start_dim=1, end_dim=-1)\n",
       "      (enemy_visible_mask): Flatten(start_dim=1, end_dim=-1)\n",
       "      (map_explored_status): Flatten(start_dim=1, end_dim=-1)\n",
       "      (map_features_energy): Flatten(start_dim=1, end_dim=-1)\n",
       "      (map_features_tile_type): Flatten(start_dim=1, end_dim=-1)\n",
       "      (match_steps): Flatten(start_dim=1, end_dim=-1)\n",
       "      (my_spawn_location): Flatten(start_dim=1, end_dim=-1)\n",
       "      (relic_nodes): Flatten(start_dim=1, end_dim=-1)\n",
       "      (relic_nodes_mask): Flatten(start_dim=1, end_dim=-1)\n",
       "      (sensor_mask): Flatten(start_dim=1, end_dim=-1)\n",
       "      (steps): Flatten(start_dim=1, end_dim=-1)\n",
       "      (team_id): Flatten(start_dim=1, end_dim=-1)\n",
       "      (team_points): Flatten(start_dim=1, end_dim=-1)\n",
       "      (team_wins): Flatten(start_dim=1, end_dim=-1)\n",
       "      (unit_active_mask): Flatten(start_dim=1, end_dim=-1)\n",
       "      (unit_energies): Flatten(start_dim=1, end_dim=-1)\n",
       "      (unit_move_cost): Flatten(start_dim=1, end_dim=-1)\n",
       "      (unit_positions): Flatten(start_dim=1, end_dim=-1)\n",
       "      (unit_sap_cost): Flatten(start_dim=1, end_dim=-1)\n",
       "      (unit_sap_range): Flatten(start_dim=1, end_dim=-1)\n",
       "      (unit_sensor_range): Flatten(start_dim=1, end_dim=-1)\n",
       "    )\n",
       "  )\n",
       "  (pi_features_extractor): CustomFeatureExtractor(\n",
       "    (cnn_extractor): OptimizedModule(\n",
       "      (_orig_mod): Sequential(\n",
       "        (0): Conv2d(4, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): SiLU()\n",
       "        (3): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): SiLU()\n",
       "        (6): Flatten(start_dim=1, end_dim=-1)\n",
       "        (7): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (extractors): ModuleDict(\n",
       "      (enemy_energies): Flatten(start_dim=1, end_dim=-1)\n",
       "      (enemy_positions): Flatten(start_dim=1, end_dim=-1)\n",
       "      (enemy_spawn_location): Flatten(start_dim=1, end_dim=-1)\n",
       "      (enemy_visible_mask): Flatten(start_dim=1, end_dim=-1)\n",
       "      (map_explored_status): Flatten(start_dim=1, end_dim=-1)\n",
       "      (map_features_energy): Flatten(start_dim=1, end_dim=-1)\n",
       "      (map_features_tile_type): Flatten(start_dim=1, end_dim=-1)\n",
       "      (match_steps): Flatten(start_dim=1, end_dim=-1)\n",
       "      (my_spawn_location): Flatten(start_dim=1, end_dim=-1)\n",
       "      (relic_nodes): Flatten(start_dim=1, end_dim=-1)\n",
       "      (relic_nodes_mask): Flatten(start_dim=1, end_dim=-1)\n",
       "      (sensor_mask): Flatten(start_dim=1, end_dim=-1)\n",
       "      (steps): Flatten(start_dim=1, end_dim=-1)\n",
       "      (team_id): Flatten(start_dim=1, end_dim=-1)\n",
       "      (team_points): Flatten(start_dim=1, end_dim=-1)\n",
       "      (team_wins): Flatten(start_dim=1, end_dim=-1)\n",
       "      (unit_active_mask): Flatten(start_dim=1, end_dim=-1)\n",
       "      (unit_energies): Flatten(start_dim=1, end_dim=-1)\n",
       "      (unit_move_cost): Flatten(start_dim=1, end_dim=-1)\n",
       "      (unit_positions): Flatten(start_dim=1, end_dim=-1)\n",
       "      (unit_sap_cost): Flatten(start_dim=1, end_dim=-1)\n",
       "      (unit_sap_range): Flatten(start_dim=1, end_dim=-1)\n",
       "      (unit_sensor_range): Flatten(start_dim=1, end_dim=-1)\n",
       "    )\n",
       "  )\n",
       "  (vf_features_extractor): CustomFeatureExtractor(\n",
       "    (cnn_extractor): OptimizedModule(\n",
       "      (_orig_mod): Sequential(\n",
       "        (0): Conv2d(4, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): SiLU()\n",
       "        (3): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): SiLU()\n",
       "        (6): Flatten(start_dim=1, end_dim=-1)\n",
       "        (7): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (extractors): ModuleDict(\n",
       "      (enemy_energies): Flatten(start_dim=1, end_dim=-1)\n",
       "      (enemy_positions): Flatten(start_dim=1, end_dim=-1)\n",
       "      (enemy_spawn_location): Flatten(start_dim=1, end_dim=-1)\n",
       "      (enemy_visible_mask): Flatten(start_dim=1, end_dim=-1)\n",
       "      (map_explored_status): Flatten(start_dim=1, end_dim=-1)\n",
       "      (map_features_energy): Flatten(start_dim=1, end_dim=-1)\n",
       "      (map_features_tile_type): Flatten(start_dim=1, end_dim=-1)\n",
       "      (match_steps): Flatten(start_dim=1, end_dim=-1)\n",
       "      (my_spawn_location): Flatten(start_dim=1, end_dim=-1)\n",
       "      (relic_nodes): Flatten(start_dim=1, end_dim=-1)\n",
       "      (relic_nodes_mask): Flatten(start_dim=1, end_dim=-1)\n",
       "      (sensor_mask): Flatten(start_dim=1, end_dim=-1)\n",
       "      (steps): Flatten(start_dim=1, end_dim=-1)\n",
       "      (team_id): Flatten(start_dim=1, end_dim=-1)\n",
       "      (team_points): Flatten(start_dim=1, end_dim=-1)\n",
       "      (team_wins): Flatten(start_dim=1, end_dim=-1)\n",
       "      (unit_active_mask): Flatten(start_dim=1, end_dim=-1)\n",
       "      (unit_energies): Flatten(start_dim=1, end_dim=-1)\n",
       "      (unit_move_cost): Flatten(start_dim=1, end_dim=-1)\n",
       "      (unit_positions): Flatten(start_dim=1, end_dim=-1)\n",
       "      (unit_sap_cost): Flatten(start_dim=1, end_dim=-1)\n",
       "      (unit_sap_range): Flatten(start_dim=1, end_dim=-1)\n",
       "      (unit_sensor_range): Flatten(start_dim=1, end_dim=-1)\n",
       "    )\n",
       "  )\n",
       "  (mlp_extractor): OptimizedModule(\n",
       "    (_orig_mod): MlpExtractor(\n",
       "      (policy_net): Sequential(\n",
       "        (0): Linear(in_features=20897, out_features=4096, bias=True)\n",
       "        (1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (2): SiLU()\n",
       "        (3): Dropout(p=0.1, inplace=False)\n",
       "        (4): Linear(in_features=4096, out_features=2048, bias=True)\n",
       "        (5): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "        (6): SiLU()\n",
       "        (7): Dropout(p=0.1, inplace=False)\n",
       "        (8): Linear(in_features=2048, out_features=1024, bias=True)\n",
       "        (9): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (10): SiLU()\n",
       "        (11): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (value_net): Sequential(\n",
       "        (0): Linear(in_features=20897, out_features=4096, bias=True)\n",
       "        (1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (2): SiLU()\n",
       "        (3): Dropout(p=0.1, inplace=False)\n",
       "        (4): Linear(in_features=4096, out_features=2048, bias=True)\n",
       "        (5): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "        (6): SiLU()\n",
       "        (7): Dropout(p=0.1, inplace=False)\n",
       "        (8): Linear(in_features=2048, out_features=1024, bias=True)\n",
       "        (9): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (10): SiLU()\n",
       "        (11): Dropout(p=0.1, inplace=False)\n",
       "        (12): Linear(in_features=1024, out_features=512, bias=True)\n",
       "        (13): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (14): SiLU()\n",
       "        (15): Dropout(p=0.1, inplace=False)\n",
       "        (16): Linear(in_features=512, out_features=256, bias=True)\n",
       "        (17): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (18): SiLU()\n",
       "        (19): Dropout(p=0.1, inplace=False)\n",
       "        (20): Linear(in_features=256, out_features=128, bias=True)\n",
       "        (21): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (22): SiLU()\n",
       "        (23): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (action_net): Linear(in_features=1024, out_features=576, bias=True)\n",
       "  (value_net): Linear(in_features=128, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'observation_space': gymnasium.spaces.dict.Dict,\n",
       " 'action_space': gymnasium.spaces.space.Space,\n",
       " 'lr_schedule': typing.Callable[[float], float],\n",
       " 'net_arch': typing.Union[list[int], dict[str, list[int]], NoneType],\n",
       " 'activation_fn': type[torch.nn.modules.module.Module],\n",
       " 'ortho_init': bool,\n",
       " 'use_sde': bool,\n",
       " 'log_std_init': float,\n",
       " 'full_std': bool,\n",
       " 'use_expln': bool,\n",
       " 'squash_output': bool,\n",
       " 'features_extractor_class': type[stable_baselines3.common.torch_layers.BaseFeaturesExtractor],\n",
       " 'features_extractor_kwargs': typing.Optional[dict[str, typing.Any]],\n",
       " 'share_features_extractor': bool,\n",
       " 'normalize_images': bool,\n",
       " 'optimizer_class': type[torch.optim.optimizer.Optimizer],\n",
       " 'optimizer_kwargs': typing.Optional[dict[str, typing.Any]]}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.policy_class.__init__.__annotations__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiInputActorCriticPolicy(\n",
       "  (features_extractor): CustomFeatureExtractor(\n",
       "    (cnn_extractor): OptimizedModule(\n",
       "      (_orig_mod): Sequential(\n",
       "        (0): Conv2d(4, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): SiLU()\n",
       "        (3): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): SiLU()\n",
       "        (6): Flatten(start_dim=1, end_dim=-1)\n",
       "        (7): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (extractors): ModuleDict(\n",
       "      (enemy_energies): Flatten(start_dim=1, end_dim=-1)\n",
       "      (enemy_positions): Flatten(start_dim=1, end_dim=-1)\n",
       "      (enemy_spawn_location): Flatten(start_dim=1, end_dim=-1)\n",
       "      (enemy_visible_mask): Flatten(start_dim=1, end_dim=-1)\n",
       "      (map_explored_status): Flatten(start_dim=1, end_dim=-1)\n",
       "      (map_features_energy): Flatten(start_dim=1, end_dim=-1)\n",
       "      (map_features_tile_type): Flatten(start_dim=1, end_dim=-1)\n",
       "      (match_steps): Flatten(start_dim=1, end_dim=-1)\n",
       "      (my_spawn_location): Flatten(start_dim=1, end_dim=-1)\n",
       "      (relic_nodes): Flatten(start_dim=1, end_dim=-1)\n",
       "      (relic_nodes_mask): Flatten(start_dim=1, end_dim=-1)\n",
       "      (sensor_mask): Flatten(start_dim=1, end_dim=-1)\n",
       "      (steps): Flatten(start_dim=1, end_dim=-1)\n",
       "      (team_id): Flatten(start_dim=1, end_dim=-1)\n",
       "      (team_points): Flatten(start_dim=1, end_dim=-1)\n",
       "      (team_wins): Flatten(start_dim=1, end_dim=-1)\n",
       "      (unit_active_mask): Flatten(start_dim=1, end_dim=-1)\n",
       "      (unit_energies): Flatten(start_dim=1, end_dim=-1)\n",
       "      (unit_move_cost): Flatten(start_dim=1, end_dim=-1)\n",
       "      (unit_positions): Flatten(start_dim=1, end_dim=-1)\n",
       "      (unit_sap_cost): Flatten(start_dim=1, end_dim=-1)\n",
       "      (unit_sap_range): Flatten(start_dim=1, end_dim=-1)\n",
       "      (unit_sensor_range): Flatten(start_dim=1, end_dim=-1)\n",
       "    )\n",
       "  )\n",
       "  (pi_features_extractor): CustomFeatureExtractor(\n",
       "    (cnn_extractor): OptimizedModule(\n",
       "      (_orig_mod): Sequential(\n",
       "        (0): Conv2d(4, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): SiLU()\n",
       "        (3): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): SiLU()\n",
       "        (6): Flatten(start_dim=1, end_dim=-1)\n",
       "        (7): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (extractors): ModuleDict(\n",
       "      (enemy_energies): Flatten(start_dim=1, end_dim=-1)\n",
       "      (enemy_positions): Flatten(start_dim=1, end_dim=-1)\n",
       "      (enemy_spawn_location): Flatten(start_dim=1, end_dim=-1)\n",
       "      (enemy_visible_mask): Flatten(start_dim=1, end_dim=-1)\n",
       "      (map_explored_status): Flatten(start_dim=1, end_dim=-1)\n",
       "      (map_features_energy): Flatten(start_dim=1, end_dim=-1)\n",
       "      (map_features_tile_type): Flatten(start_dim=1, end_dim=-1)\n",
       "      (match_steps): Flatten(start_dim=1, end_dim=-1)\n",
       "      (my_spawn_location): Flatten(start_dim=1, end_dim=-1)\n",
       "      (relic_nodes): Flatten(start_dim=1, end_dim=-1)\n",
       "      (relic_nodes_mask): Flatten(start_dim=1, end_dim=-1)\n",
       "      (sensor_mask): Flatten(start_dim=1, end_dim=-1)\n",
       "      (steps): Flatten(start_dim=1, end_dim=-1)\n",
       "      (team_id): Flatten(start_dim=1, end_dim=-1)\n",
       "      (team_points): Flatten(start_dim=1, end_dim=-1)\n",
       "      (team_wins): Flatten(start_dim=1, end_dim=-1)\n",
       "      (unit_active_mask): Flatten(start_dim=1, end_dim=-1)\n",
       "      (unit_energies): Flatten(start_dim=1, end_dim=-1)\n",
       "      (unit_move_cost): Flatten(start_dim=1, end_dim=-1)\n",
       "      (unit_positions): Flatten(start_dim=1, end_dim=-1)\n",
       "      (unit_sap_cost): Flatten(start_dim=1, end_dim=-1)\n",
       "      (unit_sap_range): Flatten(start_dim=1, end_dim=-1)\n",
       "      (unit_sensor_range): Flatten(start_dim=1, end_dim=-1)\n",
       "    )\n",
       "  )\n",
       "  (vf_features_extractor): CustomFeatureExtractor(\n",
       "    (cnn_extractor): OptimizedModule(\n",
       "      (_orig_mod): Sequential(\n",
       "        (0): Conv2d(4, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): SiLU()\n",
       "        (3): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): SiLU()\n",
       "        (6): Flatten(start_dim=1, end_dim=-1)\n",
       "        (7): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (extractors): ModuleDict(\n",
       "      (enemy_energies): Flatten(start_dim=1, end_dim=-1)\n",
       "      (enemy_positions): Flatten(start_dim=1, end_dim=-1)\n",
       "      (enemy_spawn_location): Flatten(start_dim=1, end_dim=-1)\n",
       "      (enemy_visible_mask): Flatten(start_dim=1, end_dim=-1)\n",
       "      (map_explored_status): Flatten(start_dim=1, end_dim=-1)\n",
       "      (map_features_energy): Flatten(start_dim=1, end_dim=-1)\n",
       "      (map_features_tile_type): Flatten(start_dim=1, end_dim=-1)\n",
       "      (match_steps): Flatten(start_dim=1, end_dim=-1)\n",
       "      (my_spawn_location): Flatten(start_dim=1, end_dim=-1)\n",
       "      (relic_nodes): Flatten(start_dim=1, end_dim=-1)\n",
       "      (relic_nodes_mask): Flatten(start_dim=1, end_dim=-1)\n",
       "      (sensor_mask): Flatten(start_dim=1, end_dim=-1)\n",
       "      (steps): Flatten(start_dim=1, end_dim=-1)\n",
       "      (team_id): Flatten(start_dim=1, end_dim=-1)\n",
       "      (team_points): Flatten(start_dim=1, end_dim=-1)\n",
       "      (team_wins): Flatten(start_dim=1, end_dim=-1)\n",
       "      (unit_active_mask): Flatten(start_dim=1, end_dim=-1)\n",
       "      (unit_energies): Flatten(start_dim=1, end_dim=-1)\n",
       "      (unit_move_cost): Flatten(start_dim=1, end_dim=-1)\n",
       "      (unit_positions): Flatten(start_dim=1, end_dim=-1)\n",
       "      (unit_sap_cost): Flatten(start_dim=1, end_dim=-1)\n",
       "      (unit_sap_range): Flatten(start_dim=1, end_dim=-1)\n",
       "      (unit_sensor_range): Flatten(start_dim=1, end_dim=-1)\n",
       "    )\n",
       "  )\n",
       "  (mlp_extractor): OptimizedModule(\n",
       "    (_orig_mod): MlpExtractor(\n",
       "      (policy_net): Sequential(\n",
       "        (0): Linear(in_features=20897, out_features=4096, bias=True)\n",
       "        (1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (2): SiLU()\n",
       "        (3): Dropout(p=0.1, inplace=False)\n",
       "        (4): Linear(in_features=4096, out_features=2048, bias=True)\n",
       "        (5): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "        (6): SiLU()\n",
       "        (7): Dropout(p=0.1, inplace=False)\n",
       "        (8): Linear(in_features=2048, out_features=1024, bias=True)\n",
       "        (9): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (10): SiLU()\n",
       "        (11): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (value_net): Sequential(\n",
       "        (0): Linear(in_features=20897, out_features=4096, bias=True)\n",
       "        (1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (2): SiLU()\n",
       "        (3): Dropout(p=0.1, inplace=False)\n",
       "        (4): Linear(in_features=4096, out_features=2048, bias=True)\n",
       "        (5): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "        (6): SiLU()\n",
       "        (7): Dropout(p=0.1, inplace=False)\n",
       "        (8): Linear(in_features=2048, out_features=1024, bias=True)\n",
       "        (9): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (10): SiLU()\n",
       "        (11): Dropout(p=0.1, inplace=False)\n",
       "        (12): Linear(in_features=1024, out_features=512, bias=True)\n",
       "        (13): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (14): SiLU()\n",
       "        (15): Dropout(p=0.1, inplace=False)\n",
       "        (16): Linear(in_features=512, out_features=256, bias=True)\n",
       "        (17): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (18): SiLU()\n",
       "        (19): Dropout(p=0.1, inplace=False)\n",
       "        (20): Linear(in_features=256, out_features=128, bias=True)\n",
       "        (21): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (22): SiLU()\n",
       "        (23): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (action_net): Linear(in_features=1024, out_features=576, bias=True)\n",
       "  (value_net): Linear(in_features=128, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import copy\n",
    "model.policy_2 = copy.deepcopy(model.policy)\n",
    "model.policy_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.policy.load_state_dict(torch.load(\"saved_policies_20250307_04/policy_120.pth\"))\n",
    "model.policy_2.load_state_dict(torch.load(\"saved_policies_20250307_04/policy_2_120.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_results = model.learn(total_timesteps=5050000, progress_bar=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
